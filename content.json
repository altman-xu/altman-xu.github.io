{"meta":{"title":"Altman's Blog","subtitle":"","description":"","author":"Altman","url":"https://altman-xu.github.io","root":"/"},"pages":[{"title":"About","date":"2023-11-08T10:00:20.896Z","updated":"2023-11-08T10:00:20.896Z","comments":false,"path":"about/index.html","permalink":"https://altman-xu.github.io/about/index.html","excerpt":"","text":"小学200109-200906: 苏塘小学 中学200909-201206: 大丘中学(莆田二十五中) 大学201209-201606: 兰州大学 广东亿迅科技有限公司201607-201803: 广东亿迅科技有限公司 招商局金融科技有限公司201803-202012: 招商局金融科技有限公司 深圳虾皮信息科技有限公司202012-: 深圳虾皮信息科技有限公司"},{"title":"Books","date":"2023-11-08T10:00:20.896Z","updated":"2023-11-08T10:00:20.896Z","comments":false,"path":"books/index.html","permalink":"https://altman-xu.github.io/books/index.html","excerpt":"","text":""},{"title":"Categories","date":"2023-11-08T10:00:20.896Z","updated":"2023-11-08T10:00:20.896Z","comments":false,"path":"categories/index.html","permalink":"https://altman-xu.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-11-08T10:00:20.896Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"links/index.html","permalink":"https://altman-xu.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-11-08T10:00:20.896Z","updated":"2023-11-08T10:00:20.896Z","comments":false,"path":"repository/index.html","permalink":"https://altman-xu.github.io/repository/index.html","excerpt":"","text":""},{"title":"Tags","date":"2023-11-08T10:00:20.900Z","updated":"2023-11-08T10:00:20.900Z","comments":false,"path":"tags/index.html","permalink":"https://altman-xu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"本博客搭建(v2):Hexo-GithubPages-GithubAction","slug":"Build-Blog-Hexo-GithubPages-GithubAction","date":"2023-11-08T08:29:26.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2023/11/08/Build-Blog-Hexo-GithubPages-GithubAction/","link":"","permalink":"https://altman-xu.github.io/2023/11/08/Build-Blog-Hexo-GithubPages-GithubAction/","excerpt":"","text":"本博客搭建:Hexo+GithubPages+TraviCI+pureGitHub Actions 自动部署 Hexo 博客GitHub Actions 入门教程GitHub Actions 官方文档 背景原有的 blog 搭建流程本博客搭建:Hexo+GithubPages+TraviCI+pure 随着 Travi CI 在 2020 年开始收费, 已经不可用. 所以改用新的方式搭建博客 目标 博客用一个仓库地址 source 分支用来存放 项目源代码 master 分支用来存放 hexo 编译 source 分支的文件后，生成的文件 用户只需要编写 md 博客文档, 编译生成 html 的动作交由 cicd 流程 之前的 cicd 使用 travi ci 新方式改用为 GithubAction 说明本文调整之前搭建流程的 ci 模块 本博客搭建:Hexo+GithubPages+TraviCI+pure 配置本地生成 ssh 密钥对在本地生成一对 SSH 密钥，注意更改文件名避免将正在使用的密钥覆盖。 1ssh-keygen -t ed25519 -C &quot;xuzhihua1107@gmail.com&quot; 在博客仓库的 Settings -&gt; Secrets -&gt; Actions 中添加 SSH 私钥, 内容为刚刚生成的 id_ed25519 文件的秘钥值, 命名为 SSH_DEPLOY_KEY 在部署仓库的 Settings -&gt; Deploy keys 中添加 SSH 公钥, 内容为刚刚生成的 id_ed25519.pub 文件的公钥值, 命名为 public key of SSH_DEPLOY_KEY 注意勾选 Allow write access。 注: 后续的 workflow 会使用 SSH_DEPLOY_KEY 公钥值来部署 在 _config.yml 添加内容_config.yml 1234deploy: type: git repo: git@github.com:altman-xu/altman-xu.github.io.git branch: master 编写 workflow创建 .github/workflows/githubactions.yml 写入以下内容，注意修改仓库地址和 Git 配置。此时当 push 到博客仓库时，GitHub Actions 将会自动部署 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374name: githubactions # yml文件名env: GIT_USER: altman-xu GIT_EMAIL: xuzhihua1107@gmail.com DEPLOY_REPO: altman-xu/altman-xu.github.io DEPLOY_BRANCH: master on: push: branches: - source # 仅当推送 source 分支时才运行工作流程jobs: build-and-deploy: # 任务名 runs-on: ubuntu-latest steps: - name: Checkout source # 下载 source 分支代码 uses: actions/checkout@v2 with: ref: source - name: Setup Nodejs # 安装 node.js uses: actions/setup-node@v2 with: node-version: &#x27;10&#x27; - name: Cache node modules # 缓存 node id: cache-npm uses: actions/cache@v3 env: cache-name: cache-node-modules with: # npm cache files are stored in `~/.npm` on Linux/macOS path: ~/.npm key: $&#123;&#123; runner.os &#125;&#125;-build-$&#123;&#123; env.cache-name &#125;&#125;-$&#123;&#123; hashFiles(&#x27;**/package-lock.json&#x27;) &#125;&#125; restore-keys: | $&#123;&#123; runner.os &#125;&#125;-build-$&#123;&#123; env.cache-name &#125;&#125;- $&#123;&#123; runner.os &#125;&#125;-build- $&#123;&#123; runner.os &#125;&#125;- - name: Debug Cache Hit run: echo &quot;$&#123;&#123; steps.cache-npm.outputs.cache-hit &#125;&#125;&quot; # true 代表缓存命中 ~/.npm 没有变化; 而&#x27;&#x27;代表没有命中, ~/.npm 发生变化 - name: Install npm # 只有结果是&#x27;&#x27;时才执行 if: $&#123;&#123; steps.cache-npm.outputs.cache-hit != &#x27;true&#x27; &#125;&#125; continue-on-error: true run: npm install # 在根目录安装站点需要的依赖 - name: Install npm hexo # 安装依赖 # if: $&#123;&#123; steps.cache-npm.outputs.cache-hit != &#x27;true&#x27; &#125;&#125; # 缓存暂时不能对 hexo 相关生效, 奇怪 run: | npm install hexo-cli -g # 在 CI 环境内安装 Hexo npm install hexo-wordcount --save # 安装插件 hexo-wordcount npm install hexo-generator-json-content --save # 安装插件 hexo-generator-json-content npm install hexo-generator-feed --save # 安装插件 hexo-generator-feed npm install hexo-generator-sitemap --save # 安装插件 hexo-generator-sitemap npm install hexo-generator-baidu-sitemap --save # 安装插件 hexo-generator-baidu-sitemap npm install hexo-deployer-git --save # 安装插件 用来执行 hexo deploy - name: Setup Git # 设置 git 环境变量 run: | git config --global user.name $GIT_USER git config --global user.email $GIT_EMAIL - name: Setup SSH Key # 设置 sshkey run: | mkdir -p ~/.ssh echo &quot;$&#123;&#123; secrets.SSH_DEPLOY_KEY &#125;&#125;&quot; &gt; ~/.ssh/id_ed25519 chmod 600 ~/.ssh/id_ed25519 ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts - name: hexo generate run: | hexo clean hexo generate - name: hexo deploy run: | hexo deploy cicd 执行每次在 source 分支, 编写新博客 md 文件, 提交到 git 远程后，都会触发 cicd 流程, 如下图所示, 可以点击进去查看 cicd 执行的每个步骤","categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"}]},{"title":"Life-30","slug":"Life-30","date":"2023-11-07T09:51:00.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2023/11/07/Life-30/","link":"","permalink":"https://altman-xu.github.io/2023/11/07/Life-30/","excerpt":"","text":"一眨眼, 已经 30 了 1993-2023","categories":[{"name":"Life","slug":"Life","permalink":"https://altman-xu.github.io/categories/Life/"}],"tags":[{"name":"Life","slug":"Life","permalink":"https://altman-xu.github.io/tags/Life/"}]},{"title":"博客重启","slug":"Blog-Restart-2023","date":"2023-10-25T08:10:10.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2023/10/25/Blog-Restart-2023/","link":"","permalink":"https://altman-xu.github.io/2023/10/25/Blog-Restart-2023/","excerpt":"","text":"重新开始重新打开我的 博客git仓库, 发现上一次编辑是 2021.07.22, 已经两年多了. 重新开始 blog 网页地址 git 仓库地址 old https://altman-xu.github.io/xuzhihua/ https://github.com/altman-xu/xuzhihua new https://altman-xu.github.io/ https://github.com/altman-xu/altman-xu.github.io 操作1234567891011121314151617181920212223242526272829## 1. 安装 hexobrew install hexo## 2. 在 ~/Documents 目录下 clone 博客仓库cd ~/Documentsgit clone git@github.com:altman-xu/altman-xu.github.io.git## 3. 进入 altman-xu.github.io 目录, 切换到 source 分支cd altman-xu.github.iogit checkout source## 4. 启动 hexohexo s## 5. 提示启动失败ERROR Cannot find module &#x27;hexo&#x27; from &#x27;/Users/zhihua.xu/Documents/altman-xu.github.io&#x27;ERROR Local hexo loading failed in ~/Documents/altman-xu.github.ioERROR Try running: &#x27;rm -rf node_modules &amp;&amp; npm install --force&#x27;## 执行提示的命令rm -rf node_modules &amp;&amp; npm install --force## 6. 再次启动 hexohexo s## 成功, 然后退出## 7. 创建新文档编辑hexo new &quot;My New Post&quot;## 8. 查看效果hexo s## 点击 http://localhost:4000 进入效果页面## 9. 提交 source 分支改动, 远程会 TraviCI 自动编译到 master 分支","categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"}]},{"title":"Elasticsearch-AdvanceSearch","slug":"Elasticsearch-AdvanceSearch","date":"2021-07-21T08:09:32.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/07/21/Elasticsearch-AdvanceSearch/","link":"","permalink":"https://altman-xu.github.io/2021/07/21/Elasticsearch-AdvanceSearch/","excerpt":"","text":"批量导入数据将 account.json 的数据加载到 elastic 中数据类似如下(2条) 1234&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;6&quot;&#125;&#125;&#123;&quot;account_number&quot;:6,&quot;balance&quot;:5686,&quot;firstname&quot;:&quot;Hattie&quot;,&quot;lastname&quot;:&quot;Bond&quot;,&quot;age&quot;:36,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;671 Bristol Street&quot;,&quot;employer&quot;:&quot;Netagy&quot;,&quot;email&quot;:&quot;hattiebond@netagy.com&quot;,&quot;city&quot;:&quot;Dante&quot;,&quot;state&quot;:&quot;TN&quot;&#125; 12345678## cd account.json 文件所在的目录curl -XPOST &quot;localhost:9200/bank/_bulk?pretty&amp;refresh&quot; -H &quot;Content-Type: application/json&quot; --data-binary &quot;@accounts.json&quot;curl -XGET &quot;localhost:9200/_cat/indices?v&quot;## output 可以看到 1000 个 doc 已经存储到 bank 索引中了health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open bank qerxmeePRsmIeXoZ58eNsQ 1 1 1000 0 396.8kb 396.8kbyellow open customer LbQLl0UQTSOPnn54wQwA2g 1 1 1 1 4.3kb 4.3kb 搜索 _search注意，一旦获得了搜索结果，Elasticsearch就会结束这次搜索，不会再维护任何服务端资源，也没有结果游标，这与其他很多平台，如SQL，不一样。 通过 uri 传递参数123456GET /bank/_search?q=*&amp;sort=account_number:asc&amp;prettycurl -XGET &quot;localhost:9200/bank/_search?q=*&amp;sort=account_number:asc&amp;pretty&quot;## 参数说明# q=* 搜索索引中的所有文档# sort=account_number:asc 搜索结果以字段account_number升序排列# pretty 返回结果以漂亮的JSON格式打印 通过 request body 传递参数12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;account_number&quot;: &quot;asc&quot; &#125; ]&#125;curl -XGET &quot;localhost:9200/bank/_search&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;sort&quot;: [ &#123;&quot;account_number&quot;: &quot;asc&quot;&#125; ]&#125;&#x27; 响应数据12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot; : 22, // 搜索时间(毫秒) &quot;timed_out&quot; : false, // 搜索是否超时 &quot;_shards&quot; : &#123; // 搜索了多少分片，搜索分片的成功/失败计数 &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; // 搜索结果 &quot;total&quot; : &#123; // 搜索命中总数信息 &quot;value&quot; : 1000, // 命中总数 &quot;relation&quot; : &quot;eq&quot; // 取值eq(等于)/gte(大于等于)，表示hits.total.value与实际的搜索命中数量的关系 // 如果搜索结果很多，超过一定数量后，通常就不再统计，只是笼统地表示为：搜索结果超过XXXX个。hits.total的准确性由请求参数track_total_hits控制，当track_total_hits为true时，搜索时将精确地跟踪总命中数(“relationship”:“eq”)。track_total_hits默认值为10,000，意味着总命中数可以精确地跟踪到10000个文档，如果超过10000，会表示为超过10000个结果 &#125;, &quot;max_score&quot; : null, // hits._score 与 max_score – 分数是衡量文档与搜索条件匹配程度的一个指标。分数越高，文档越相关，分数越低，文档越不相关。并不总是需要生成分数，需不需要Elasticsearch会自动判断，以避免计算无用的分数。 &quot;hits&quot; : [ // 实际的搜索结果数组(默认为前10个文档) &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;_score&quot; : null, &quot;_source&quot; : &#123; &quot;account_number&quot; : 0, &quot;balance&quot; : 16623, &quot;firstname&quot; : &quot;Bradshaw&quot;, &quot;lastname&quot; : &quot;Mckenzie&quot;, &quot;age&quot; : 29, &quot;gender&quot; : &quot;F&quot;, &quot;address&quot; : &quot;244 Columbus Place&quot;, &quot;employer&quot; : &quot;Euron&quot;, &quot;email&quot; : &quot;bradshawmckenzie@euron.com&quot;, &quot;city&quot; : &quot;Hobucken&quot;, &quot;state&quot; : &quot;CO&quot; &#125;, &quot;sort&quot; : [ // 结果排序键(如果按分数排序，则忽略) 0 ] &#125;, ... ] &#125;&#125; Query DSL(Query domain-specific language)Elasticsearch提供了一种json风格的查询语言 sort, from, size 排序,分页12345678910curl -XGET &quot;localhost:9200/bank/_search?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;sort&quot;: [ &#123;&quot;account_number&quot;: &quot;asc&quot;&#125; ], &quot;from&quot;:5, &quot;size&quot;:5&#125;&#x27; query 表示这次查询的定义match_all 表示查询类型-匹配所有文档sort 指定排序from 参数(基于0)指定从哪个文档序号开始(默认0)，size参数指定返回多少个文档(默认10),这两个参数对于搜索结果分页非常有用 _source 指定返回的字段默认情况下， 搜索结果中包含了完整的json文档( _source 字段),如果不希望返回源文档全部内,可以设置要返回的字段 123456curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;:&#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;_source&quot;:[&quot;account_number&quot;, &quot;balance&quot;]&#125;&#x27; match_all 匹配所有文档12345curl -XGET &quot;localhost:9200/bank/_search?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;&#125;&#x27; match 匹配查询返回 account_number 为 20 的所有账户1234567curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&quot;account_number&quot;: 20&#125; &#125;&#125;&#x27; 返回 address 包含 mill 的所有账户1234567curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&quot;address&quot;: &quot;mill&quot;&#125; &#125;&#125;&#x27; 返回 address 包含 mill 或 lane 的所有账户1234567curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&quot;address&quot;: &quot;mill lane&quot;&#125; &#125;&#125;&#x27; match_phrase 匹配整个短语返回 address 包含 “mill lane” 的所有账户1234567curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123;&quot;address&quot;: &quot;mill lane&quot;&#125; &#125;&#125;&#x27; bool 布尔查询布尔查询使用布尔逻辑，将小查询组合成大查询 bool must 包含两个 match,逻辑与返回地址中包含 mill 且也包含 lane 的账户must 下所有匹配条件为真，文档才视为匹配 123456789101112curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;mill&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;lane&quot;&#125;&#125; ] &#125; &#125;&#125;&#x27; bool should 包含两个 match,逻辑或返回地址中包含 mill 或也包含 lane 的账户must 下任意一个匹配条件为真，文档就视为匹配 123456789101112curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;mill&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;lane&quot;&#125;&#125; ] &#125; &#125;&#125;&#x27; bool must_not包含两个 match,逻辑与非返回地址中既不包含“mill”也不包含“lane”的帐户bool must_not子句包含的匹配条件全部为假，文档将被视为匹配 123456789101112curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;mill&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;lane&quot;&#125;&#125; ] &#125; &#125;&#125;&#x27; bool 查询中同时组合 must、should和must_not (解决should 不生效问题)当使用should查询时，如果包含了must或者filter查询，那么should的查询语句就不是或者的意思了,而是有或者没有都行的含义。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051## 解决方法 1: 使用 minimum_should_matchcurl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125; ], &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;Jackson&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;Suydam&quot;&#125;&#125; ], &quot;minimum_should_match&quot;: 1 &#125; &#125;&#125;&#x27;## 解决方法 2: 应先满足must，然后在must的基础上进行should查询,即转换成复杂的组合查询，就是满足一定的条件下，再满足条件1或者满足条件2或者满足条件3curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; // 先满足前置条件 &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125; ] &#125; &#125;, &#123; // 再满足后置条件 &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;Jackson&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address&quot;: &quot;Suydam&quot;&#125;&#125; ] &#125; &#125; ] &#125; &#125;&#125;&#x27; filter 过滤_score(分数)字段是衡量文档与搜索条件匹配程度的一个指标。分数越高，文档越相关，分数越低，文档越不相关。并不总是需要生成分数，需不需要Elasticsearch会自动判断，以避免计算无用的分数。布尔查询还支持filter子句，用于设置过滤条件。过滤条件不影响文档的相关性分数。 返回 balance 在 20000-30000 之间的账户1234567891011121314151617curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125;&#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;balance&quot;: &#123; &quot;gte&quot;: 20000, &quot;lte&quot;: 30000 &#125; &#125; &#125; &#125; &#125;&#125;&#x27; aggs 聚合聚合提供了对数据进行分组、统计的能力，类似于SQL中GROUP by和SQL聚合函数。在Elasticsearch中，可以同时返回搜索结果及其聚合计算结果，这是非常强大和高效的。 terms 账户按所在州分组，统计每组账户数量，然后返回前10条目类似sql中的 SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC LIMIT 10; 注: size=0 表示不显示搜索结果，我们只想看到聚合结果 123456789101112curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; // group_by_state 不是关键字，只是结果展示的名称 &quot;terms&quot;: &#123; // 这个才是关键字 &quot;field&quot;: &quot;state.keyword&quot; &#125; &#125; &#125;&#125;&#x27; terms, avg 所有账户按州计算平均账户余额,返回前10条目,按账户数量降序排列12345678910111213141516171819202122curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; // 先按照州聚合 &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot;, &quot;order&quot;: &#123; &quot;average_balance&quot;: &quot;desc&quot; &#125; &#125;, &quot;aggs&quot;: &#123; // 再计算每个州的平均账户余额 &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125;&#125;&#x27; range, term, avg 先按照年龄段分组，然后按性别分组，统计每个年龄等级，每种性别的平均账户余额12345678910111213141516171819202122232425262728293031323334353637383940curl -XGET &#x27;localhost:9200/bank/_search?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_age&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 20, &quot;to&quot;: 30 &#125;, &#123; &quot;from&quot;: 30, &quot;to&quot;: 40 &#125;, &#123; &quot;from&quot;: 40, &quot;to&quot;: 50 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_gender&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;gender.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;&#x27; 参考资料Elasticsearch 搜索数据ES多条件查询must和should不能同时生效问题es bool多条件查询should和must同时使用注意","categories":[],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://altman-xu.github.io/tags/Elasticsearch/"}]},{"title":"Elasticsearch-API","slug":"Elasticsearch-API","date":"2021-07-21T03:00:35.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/07/21/Elasticsearch-API/","link":"","permalink":"https://altman-xu.github.io/2021/07/21/Elasticsearch-API/","excerpt":"","text":"命令形式API格式在 kibana 中执行 1GET /_cat/health?v curl访问API在 terminal 中执行 1curl -XGET &quot;localhost:9200/_cat/shards?v&quot; 集群操作获取健康信息123## outputip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 59 97 7 1.98 dimr * C02CF1LYMD6Q 获取分片信息12345curl -XGET &quot;localhost:9200/_cat/shards?v&quot;## outputindex shard prirep state docs store ip nodecustomer 0 p STARTED 0 208b 127.0.0.1 C02CF1LYMD6Qcustomer 0 r UNASSIGNED 获取节点信息1234curl -XGET &quot;localhost:9200/_cat/nodes?v&quot;## outputepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1626836684 03:04:44 elasticsearch_brew yellow 1 1 2 2 0 0 1 0 - 66.7% 索引操作 命令末尾追加pretty,可以漂亮地打印JSON响应(如果有的话) 创建索引1234567curl -XPUT &#x27;localhost:9200/customer?pretty&#x27;## output&#123; &quot;acknowledged&quot; : true, &quot;shards_acknowledged&quot; : true, &quot;index&quot; : &quot;customer&quot;&#125; 查询索引 显示所有索引信息, 若索引太多，建议重定向到文件中，避免终端显示不完整 curl -XGET &#39;localhost:9200/_cat/indices?v&#39; &gt; tmp.log 1234curl -XGET &#x27;localhost:9200/_cat/indices?v&#x27;## outputhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open customer 1ROsx5JQTluas2hEGLh0Qg 1 1 0 0 208b 208b 删除索引12345curl -XDELETE &#x27;localhost:9200/customer?pretty&#x27;## output&#123; &quot;acknowledged&quot; : true&#125; 文档操作Elasticsearch并不要求，先要有索引，才能将文档编入索引。创建文档时，如果指定索引不存在，将自动创建 创建文档将一个客户文档放到 customer 索引中, ID 为1 12345678910111213141516171819202122232425##API:PUT /customer/_doc/1?pretty&#123;&quot;name&quot;:&quot;John Doe&quot;&#125;## curl命令访问API:curl -XPUT &quot;localhost:9200/customer/_doc/1?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;&#x27;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1&#125; 查询文档在 customer 索引中查询 文档 id 为 1 的数据 1234567891011121314curl -XGET &quot;localhost:9200/customer/_doc/1?pretty&quot;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;John Doe&quot; &#125;&#125; 更新文档 Elasticsearch实际上并没有在底层执行就地更新，而是先删除旧文档，再添加新文档 修改数据将 customer 索引中文档 ID 为 1 的 name 更改为 “Jane Doe” 12345678910111213141516171819202122232425262728293031323334curl -XPOST &quot;localhost:9200/customer/_update/1?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;doc&quot;: &#123;&quot;name&quot;: &quot;Jane Doe&quot;&#125;&#125;&#x27;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 2, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1&#125;## 再次查询，可以看到数据已经修改了curl -XGET &quot;localhost:9200/customer/_doc/1?pretty&quot;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 2, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;Jane Doe&quot; &#125;&#125; 添加字段把文档(ID为1)中的name字段更改为 “Altman”，再添加一个年龄字段: age 123456789101112131415161718192021222324252627282930313233343536curl -XPOST &quot;localhost:9200/customer/_update/1?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;doc&quot;: &#123;&quot;name&quot;: &quot;Altman&quot;, &quot;age&quot;: 18&#125;&#125;&#x27;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 3, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1&#125;## 再次查询，可以看到数据已经修改了curl -XGET &quot;localhost:9200/customer/_doc/1?pretty&quot;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 3, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;Altman&quot;, &quot;age&quot; : 18 &#125;&#125; 脚本执行使用脚本将年龄增加5岁 123456789101112131415161718192021222324252627282930313233343536curl -XPOST &quot;localhost:9200/customer/_update/1?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123; &quot;script&quot; : &quot;ctx._source.age += 5&quot;&#125;&#x27;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 4, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 3, &quot;_primary_term&quot; : 1&#125;## 再次查询，可以看到数据已经修改了curl -XGET &quot;localhost:9200/customer/_doc/1?pretty&quot;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 4, &quot;_seq_no&quot; : 3, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;Altman&quot;, &quot;age&quot; : 23 &#125;&#125; 删除文档删除文档 ID 为 2 的数据，注 该 ID 不存在 12345678910111213141516curl -XDELETE &quot;localhost:9200/customer/_doc/2?pretty&quot;## output&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;not_found&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 4, &quot;_primary_term&quot; : 1&#125; 批处理先将 customer 索引删除，重建，然后执行下面 某个操作失败不会导致批量API执行中断，剩下的操作将继续执行。当_bulk API返回时，它将为每个操作提供一个状态(与发送操作的顺序相同)，以便检查某个特定操作是否失败。 在一个批量操作中,创建两个文档123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687curl -XPOST &#x27;localhost:9200/customer/_bulk?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d &#x27;&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;name&quot;: &quot;John, Doe&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;&#123;&quot;name&quot;: &quot;Jane, Doe&quot;&#125;&#x27;## output&#123; &quot;took&quot; : 231, &quot;errors&quot; : false, &quot;items&quot; : [ &#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 &#125; &#125;, &#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 &#125; &#125; ]&#125;## 查看这个索引里面的所有数据curl -XGET &#x27;localhost:9200/customer/_search?q=*&amp;pretty&#x27;## output&#123; &quot;took&quot; : 97, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : &#123; &quot;value&quot; : 2, &quot;relation&quot; : &quot;eq&quot; &#125;, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;John, Doe&quot; &#125; &#125;, &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;name&quot; : &quot;Jane, Doe&quot; &#125; &#125; ] &#125;&#125; 在一个批量操作中,更新第一个文档,删除第二个文档 对于delete操作，只需提供被删除文档的ID即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546curl -XPOST &#x27;localhost:9200/customer/_bulk?pretty&#x27; -H &#x27;Content-Type: application/json&#x27; -d &#x27;&#123;&quot;update&quot;: &#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;doc&quot;: &#123;&quot;name&quot;: &quot;Johe Doe becomes Jane Doe&quot; &#125;&#125;&#123;&quot;delete&quot;: &#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;&#x27;## output&#123; &quot;took&quot; : 52, &quot;errors&quot; : false, &quot;items&quot; : [ &#123; &quot;update&quot; : &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 2, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1, &quot;status&quot; : 200 &#125; &#125;, &#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 2, &quot;result&quot; : &quot;deleted&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 3, &quot;_primary_term&quot; : 1, &quot;status&quot; : 200 &#125; &#125; ]&#125; 参考资料Elasticsearch 使用集群","categories":[],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://altman-xu.github.io/tags/Elasticsearch/"}]},{"title":"Elasticsearch-Install","slug":"Elasticsearch-Install","date":"2021-07-21T02:50:09.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/07/21/Elasticsearch-Install/","link":"","permalink":"https://altman-xu.github.io/2021/07/21/Elasticsearch-Install/","excerpt":"","text":"brew 单机安装123brew install elasticsearchbrew services start elasticsearchbrew services list 单机安装 + 插件 下载 https://www.elastic.co/cn/downloads/elasticsearch 得到 elasticsearch-7.12.0-darwin-x86_64.tar.gz 解压压缩包，得到 elasticsearch-7.12.0 cd /Users/zhihua.xu/ALTMAN_WORKSPACE/distributed_workspace/elasticsearch-7.12.0/bin 以下命令都是在此目录下执行 执行 ./elasticsearch 即可启动本机 elasticsearch 服务， 通过 web 页面查看服务 http://localhost:9200 查看本机已安装的elasticsearch插件 ./elasticsearch-plugin list 安装插件: ./elasticsearch-plugin install analysis-icu 重启 elasticsearch 服务， 通过web页面查看插件: http://localhost:9200/_cat/plugins 集群安装 下载 https://www.elastic.co/cn/downloads/elasticsearch 得到 elasticsearch-7.12.0-darwin-x86_64.tar.gz 解压压缩包，得到 elasticsearch-7.12.0 cd /Users/zhihua.xu/ALTMAN_WORKSPACE/distributed_workspace/elasticsearch-7.12.0/bin 以下命令都是在此目录下执行 启动命令:./elasticsearch -E node.name=node1 -E cluster.name=altman_cluster_test -E path.data=node1_data -d./elasticsearch -E node.name=node2 -E cluster.name=altman_cluster_test -E path.data=node2_data -d./elasticsearch -E node.name=node3 -E cluster.name=altman_cluster_test -E path.data=node3_data -d 命令说明: node.name 指定节点名字； cluster.name 指定集群名字； path.data 指定文件名字； -d 后台运行打开浏览器验证 http://localhost:9200/ 里面可以看到 cluster_name 信息http://localhost:9200/_cat/nodes 查看集群节点信息 删除进程ps | grep elasticsearchkill pid 参考资料Elasticsearch 安装","categories":[],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://altman-xu.github.io/tags/Elasticsearch/"}]},{"title":"Elasticsearch-Concept","slug":"Elasticsearch-Concept","date":"2021-07-21T02:41:50.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/07/21/Elasticsearch-Concept/","link":"","permalink":"https://altman-xu.github.io/2021/07/21/Elasticsearch-Concept/","excerpt":"","text":"近实时(Near Realtime / NRT)Elasticsearch是一个近实时的搜索平台，从生成文档索引到文档成为可搜索，有一个轻微的延迟(通常是一秒钟)。 集群(Cluster)集群是一个或多个节点(服务器)的集合。集群中的节点一起存储数据，对外提供搜索功能。集群由一个唯一的名称标识，该名称默认是“elasticsearch”。集群名称很重要，节点都是通过集群名称加入集群。 集群不要重名，取名一般要有明确意义，否则会引起混乱。例如，开发、测试和生产集群的名称可以使用logging-dev、logging-test和logging-prod。 集群节点数不受限制，可以只有一个节点。 节点(Node)节点是一个服务器，属于某个集群。节点存储数据，参与集群的索引和搜索功能。与集群一样，节点也是通过名称来标识的。默认情况下，启动时会分配给节点一个UUID（全局惟一标识符）作为名称。如有需要，可以给节点取名，通常取名时应考虑能方便识别和管理。 默认情况下，节点加入名为elasticsearch的集群，通过设置节点的集群名，可加入指定集群。 索引(Index)索引是具有某种特征的文档集合，相当于一本书的目录。例如，可以为客户数据建立索引，为订单数据建立另一个索引。索引由名称标识(必须全部为小写)，可以使用该名称，对索引中的文档进行建立索引、搜索、更新和删除等操作。 一个集群中，索引数量不受限制。 文档(Document)文档是可以建立索引的基本信息单元，相当于书的具体章节。例如，可以为单个客户创建一个文档，为单个订单创建另一个文档。文档用JSON (JavaScript对象表示法)表示。在索引中，理论上可以存储任意数量的文档。 分片与副本(Shards &amp; Replicas)索引可能存储大量数据，数据量可能超过单个节点的硬件限制。例如，一个索引包含10亿个文档，将占用1TB的磁盘空间，单个节点的磁盘放不下。 Elasticsearch提供了索引分片功能。创建索引时，可以定义所需的分片数量。每个分片本身都是一个功能齐全，独立的“索引”，可以托管在集群中的任何节点上。 分片之所以重要，主要有2个原因: 允许水平切分内容，以便内容可以存储到普通的服务器中 允许跨分片操作（如查询时，查询多个分片），提高性能/吞吐量 分片如何部署、如何跨片搜索完全由Elasticsearch管理，对外是透明的。 网络环境随时可能出现故障，如果某个分片/节点由于某种原因离线或消失，那么使用故障转移机制是非常有用的，强烈建议使用这种机制。为此，Elasticsearch允许为分片创建副本。 副本之所以重要，主要有2个原因: 在分片/节点失败时提供高可用性。因此，原分片与副本不应放在同一个节点上。 扩展吞吐量，因为可以在所有副本上并行执行搜索。 总而言之，索引可以分片，索引分片可以创建副本。复制后，每个索引将具有主分片与副本分片。 创建索引时，可以为每个索引定义分片和副本的数量。之后，还可以随时动态更改副本数量。您可以使用 _shrink 和 _split api更改现有索引的分片数量，但动态修改副本数量相当麻烦，最好还是预先计划好分片数量。 默认情况下，Elasticsearch中的每个索引分配一个主分片和一个副本。如果集群中有两个节点，就可以将索引主分片部署在一个节点，副本分片放在另一个节点，提高可用性。 每个Elasticsearch分片都是一个Lucene索引。Lucene索引中的文档数量有限制，在LUCENE-5843中，极限是2,147,483,519(= 整数的最大值 – 128)个文档。可以使用 curl -XGET &quot;localhost:9200/_cat/shards&quot; API监视分片大小。 流程图 参考资料Elasticsearch 基本概念","categories":[],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://altman-xu.github.io/tags/Elasticsearch/"}]},{"title":"Assembly-Instructions","slug":"Assembly-Instructions","date":"2021-06-30T01:59:21.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/06/30/Assembly-Instructions/","link":"","permalink":"https://altman-xu.github.io/2021/06/30/Assembly-Instructions/","excerpt":"","text":"字节 描述 b 1 bytes 字节 w 2 bytes 字 l 4 bytes 双字 q 8 bytes 四字 指令 指令 效果 描述 MOV S,D D&lt;-S 传送 movb 传送字节 movw 传送字 movb 传送双字 movq 传送四字 movabsq I,R R&lt;-I 传送绝对的四字 MOV 源和目的类型的5种可能组合 指令 说明 字节 movl $0x4050,%eax Immediate–Register 4 bytes movw %bp,%sp Register–Register 2 bytes movb (%rdi,%rcx),%al Memory–Register 1 bytes movb $-17,(%rsp) Immediate–Memory 1 bytes movq %rax,-12(%rbp) Register–Memory 8 bytes 指令 效果 描述 leaq S,D D &lt;-&amp;S 加载有效地址 – – – INC D D &lt;- D+1 加1 DEC D D &lt;- D-1 减1 NEG D D &lt;- -D 取负 NOT D D &lt;- ~D 取补 – – – ADD S,D D &lt;- D+S 加 SUB S,D D &lt;- D-S 减 IMUL S,D D &lt;- D*S 乘 XOR S,D D &lt;- D~S 异或 OR S,D D &lt;- D S AND S,D D &lt;- D&amp;S 与 – – – SAL k,D D &lt;- D &lt;&lt;k 左移 SHL k,D D &lt;- D &lt;&lt;k 左移(等同于SAL) SAR k,D D &lt;- D &gt;&gt;ak 算术右移 SHR k,D D &lt;- D &gt;&gt;lk 逻辑右移 CMP TESTcmp 和 test 指令不修改任何寄存器的值，只设置条件码 cmp 根据两个操作数之差来设置条件码，除了只设置条件码而不更新目的寄存器外，cmp指令与sub指令的行为是一样的。如果两个操作数相等，这些指令会将零标志设置为 1，而其他的标志可以用来确定两个操作数之间的大小关系 test 除了只设置条件码而不更新目的寄存器外，指令与 and 指令是一样的。 典型用法是两个操作数是一样的(例如 testq %rax,%rax 用来检查 %rax是负数、零还是正数)，或其中的一个操作数是一个掩码，用来只是哪些位应该被测试 指令 基于 描述 CMP S1, S2 S2-S1 比较 cmpb 比较字节 cmpw 比较字 cmpl 比较双字 cmpq 比较四字 – – – TEST S1, S2 S2&amp;S1 测试 testb 测试字节 testw 测试字 testl 测试双字 testq 测试四字 条件码程序状态字PSW（Program State Word） 除了整数寄存器，CPU还维护一组单个位的条件码寄存器，他们描述了最近的算术或逻辑操作的属性。可以检测这些寄存器来执行条件分支指令 31··· 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 ID VIP VIF AC VM O RF NT IOPL OF DF IF TF SF ZF x AF x PF x CF 条件码 标志 说明 CF Carry Flag 进位标志 最近的操作使最高位产生了进位，可用来检查无符号操作的溢出 ZF Zero Flag 零标志 最近的操作得出的结果为0 SF Sign flag 符号标志 最近的操作得到的结果为负数 OF Overflow 溢出标志 最近的操作导致一个补码溢出–正溢出或负溢出 PF Panty Flag 偶标志 AF Auxiliary 半进/借位 TF Trap Flag 陷阱 IF Interrupt 允许中断 DF Direction 增量方向 VIF 虚拟中断标志位 VP 虚拟中断待决标志位 IOPL IO特权级别 条件码同城不会直接读取，常用的使用方法有三种 (set指令) 根据条件码的某种组合，讲一个字节设置为0或1 (jump指令) 可以条件跳转到程序的某个其他地方 (cmove指令) 可以有条件的传送数据 SETset指令，每条指令根据条件码的组合，将一个字节设置为0或1。有些指令有同义名，也就是同一条机器指令有别的名字 指令 同义名 效果 设置条件 sete D setz D &lt;- ZF 相等/零 setne D setnz D &lt;- ~ZF 不等/非零 sets D D &lt;- SF 负数 setns D D &lt;- ~SF 非负数 setg D setnle D &lt;- (SF^OF)&amp;ZF 大于(有符号&gt;) setge D setnl D &lt;- ~(SF^OF) 大于等于(有符号&gt;=) setl D setnge D &lt;- SF^OF 小于(有符号&lt;) setle D setng D &lt;- (SF^OF) ZF seta D setnbe D &lt;- CF&amp;ZF 超过(无符号&gt;) setae D setnb D &lt;- ~CF 超过或相等(无符号&gt;=) setb D setnae D &lt;- CF 低于(无符号&lt;) setbe D setna D &lt;- CF|ZF 低于或相等(无符号&lt;=) JUMP当条件满足时，这些指令会调整到一条带标号的目的地 指令 同义名 跳转条件 描述 jmp Label 1 直接跳转 jmp *Operand 1 间接跳转 je Label jz ZF 相等/零 jne Label jnz -ZF 不相等/非零 js Label SF 负数 jns Label ~SF 非负数 jg Label jnle (SF^OF)&amp;ZF 大于(有符号&gt;) jge Label jnl ~(SF^OF) 大于或等于(有符号&gt;=) jl Label jnge SF^OF 小于(有符号&lt;) jle Label jng (SF^OF)|ZF 小于或等于(有符号&lt;=) ja Label jnbe CF&amp;ZF 超过(无符号&gt;) jae Label jnb ~CF 超过或相等(无符号&gt;=) jb Label jnae CF 低于(无符号&lt;) jbe Label jna CF ZF CMOVE条件传送指令。当传送条件满足时，指令吧源值S复制到目的地R 指令 同义名 传送条件 描述 cmove S,R cmovz ZF 相等/零 cmovne S,R cmovnz ~ZF 不相等/非零 cmovs S,R SF 负数 cmovns S,R ~SF 非负数 cmovg S,R cmovnle (SF^OF)&amp;ZF 大于(有符号&gt;) cmovge S,R cmovnl ~(SF^OF) 大于或等于(有符号&gt;=) cmovgl S,R cmovnge SF^OF 小于(有符号&lt;) cmovgle S,R cmovng (SF^OF)|ZF 小于或等于(有符号&lt;=) cmova S,R cmovnbe CF&amp;ZF 超过(无符号&gt;) cmovae S,R cmovnb ~CF 超过或相等(无符号&gt;=) cmovb S,R cmovnae CF 低于(无符号&lt;) cmovbe S,R cmovna CF|ZF 低于或相等(无符号&lt;=) 条件控制转移 条件数据传送为了理解为什么基于条件数据传送的代码会比基于条件控制转移的代码性能要好，我们必须了解一些关于现代处理器如何运行的知识。 处理器通过使用流水线(pipelining)来获得高性能，在流水线中，一 条指令的处理要经过一系列的阶段，每个阶段执行所需操作的一小部分(例如，从内存取 指令、确定指令类型、从内存读数据、执行算术运算、向内存写数据，以及更新程序计数 器)。这种方法通过重叠连续指令的步骤来获得高性能，例如，在取一条指令的同时，执 行它前面一条指令的算术运算。要做到这一点，要求能够事先确定要执行的指令序列，这 样才能保持流水线中充满了待执行的指令。当机器 遇到条件跳转(也称为 “分支”)时，只 有当分支条件求值完成之后，才能决定分支往哪边走。处理器采用非常精密的分支预测逻 辑来猜测每条跳转指令是否会执行。只要它的猜测还比较可靠(现代微处理器设计试图达 到 90%以上的成功率)，指令流水线中就会充满着指令。另一方面，错误预测一个跳转， 要求处理器丢掉它为该跳转指令后所有指令已做的工作，然后再开始用从正确位置处起始 的指令去填充流水线。正如我们会看到的，这样一个错误预测会招致很严重的惩罚，浪费 大约 15~30 个时钟周期，导致程序性能严重下降。 条件控制转移 与 条件数据传送 demo 如下: 12345678910111213141516v = test-expr ? then-expr : else-expr;基于 条件控制转移 伪代码如下: (then-expr / else-expr 这两个只执行一次)if (!test-expr) goto false;v = then-expr;goto done;false: v = else-expr;done;基于 条件数据传送 伪代码如下: (then-expr / else-expr 这两个都会被执行)v = then-expr;ve = else-expr;t = test-expr;if(!t) v = ve;","categories":[],"tags":[{"name":"assembly","slug":"assembly","permalink":"https://altman-xu.github.io/tags/assembly/"}]},{"title":"Kubernetes-On-MacOS-minikube","slug":"Kubernetes-On-MacOS-minikube","date":"2021-06-29T07:18:15.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/06/29/Kubernetes-On-MacOS-minikube/","link":"","permalink":"https://altman-xu.github.io/2021/06/29/Kubernetes-On-MacOS-minikube/","excerpt":"","text":"安装软件1234brew install dockerbrew install virtualboxbrew install kubectlbrew install minikube minikube 命令start123456789101112131415161718192021## minikube 支持三种HyperKit、VirtualBox、Parallels Desktop、VMware Fusion## 设置默认 driverminikube config set driver virtualbox## 启动集群## 简单版本minikube start## 详细参数版本minikube start --v=0 --kubernetes-version v1.20.7 --cpus 4 --memory=8192 --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers --driver=virtualbox## 参数说明--v 日志等级 0 INFO level logs 1 WARNING level logs 2 ERROR level logs 3 libmachine logging 7 libmachine --debug level logging--kubernetes-version 指定版本--cpus 4 --memory=8192 指定资源--image-repository 指定镜像代理--driver=virtualbox 指定 driver, 如果设置过默认 driver 这个可以忽略 dashboard123456## 在新的终端运行命令## 打开仪表盘，默认会打开一个浏览器页面minikube dashboard## 打开仪表盘，但是不打开浏览器minikube dashboard --url addons1234567## addons 相关命令## 启用 ingressminikube addons enable ingress## 禁用 ingressminikube addons disable ingressminikube addons list service12## 运行 kubectl 创建好的服务minikube service hello-node stop delete1234## 关闭 minikube virtual machineminikube stop## 删除 minikube virtual machineminikube delete kubectl 命令deployment1234## 创建 deploymentkubectl create deployment hello-node --image=k8s.gcr.io/echoserver:1.4## 查看 deploymentkubectl get deployments event12## 查看 cluster eventskubectl get events configuration12## 查看 cubectl configurationkubectl config view pods12345678910## 查看 pod#### 查看 namespace 为 default 的 podkubectl get pods#### 查看所有 namespace 的 podkubectl get pods --all-namespaces -o wide#### 查看指定 namespace 为 kube-system 的 podkubectl get pods -n kube-system -o wide## 查询详细kubectl describe pod PodName services1234567891011121314## 查看你创建的 pod,servicekubectl get pod,svc -n kube-system## 查看 servicekubectl get services --all-namespaces## 创建 servicekubectl expose deployment hello-node --type=LoadBalancer --port=8080## 查看 servicekubectl get services --all-namespaces## 注: 对比第一次查看 service, 此时多了一个刚刚 expose 的 hello-node 服务## 原因: 默认 pod都是只在集群内部可用，只有expose之后，外部网络才可以访问到## minikube 运行服务minikube service hello-node cleanup123## 删除 service deploy, 即 清理资源kubectl delete service hello-nodekubectl delete deployment hello-node 参考资料在MacOS上安装kubernetes在MAC上安装K8S (kubernets) for Docker Desktop手摸手教你从开发到部署(CI/CD)GO微服务系列minikube docsk8s tutorials Hello Minikube","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://altman-xu.github.io/tags/k8s/"}]},{"title":"Hbase","slug":"Hbase","date":"2021-06-23T03:13:25.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/06/23/Hbase/","link":"","permalink":"https://altman-xu.github.io/2021/06/23/Hbase/","excerpt":"","text":"MacOS 本机安装运行 hbase 单机12345678910## 安装命令brew install hbase## 查看版本brew info hbase## 运行命令brew services start hbase## 查看运行状态brew services list## 进入 hbase shell 终端hbase shell ## 此命令如果无法执行，则进入 /usr/local/Cellar/hbase/2.4.3/bin 目录 执行 sh ./hbase shell 查看版本信息截图如下: MacOS 连接远程 hbase 集群123456789101112## 通过配置 ZK 地址 来连接对应远程的 hbase 集群cd /usr/local/Cellar/hbase/2.4.3/libexec/confvim hbase-site.xml## 在这个文件的 &lt;configuration&gt; 节点下添加如下子节点## zk:2181,zk:2181,zk:2181 为集群的 zk 连接地址&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;zk:2181,zk:2181,zk:2181&lt;/value&gt;&lt;/property&gt;## 然后执行命令连接远程 hbase, 可执行 list 命令查看所有表，验证是否连接到远程 hbasehbase shell Hbase 命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697## 查看所有表list## 查看某个表结构，例如 scoresdescribe &quot;scores&quot;## 删除表 scores , 删除需要先 disable 再 dropdisable &quot;scores&quot;drop &quot;scores&quot;## 删除 匹配表drop_all &#x27;t.*&#x27;## 创建表 scores 表，包含两个列族 grade 、 coursecreate &#x27;scores&#x27;,&#x27;grade&#x27;,&#x27;course&#x27;## put 命令往表添加数据 ## 格式: put &#x27;t1&#x27;, &#x27;r1&#x27;, &#x27;c1&#x27;, &#x27;value&#x27;, ts1 ## t1指表名，r1指行键名，c1指列名，value指单元格值。ts1指时间戳，一般都省略掉了## 一次 put 只能往表里面 put 一个单元格数据put &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;grade:&#x27;, &#x27;5&#x27;put &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;course:math&#x27;, &#x27;99&#x27;put &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;course:english&#x27;, &#x27;98&#x27; ## course 列族包含多个列，需要 列族:列 指定对应的列名put &#x27;scores&#x27;, &#x27;Tom&#x27;, &#x27;grade&#x27;, &#x27;5&#x27; ## grade 列族就只有一列 故 : 可以省略## get 命令查询表数据get &#x27;scores&#x27;, &#x27;Altman&#x27;get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;grade&#x27;get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;grade&#x27;, &#x27;course:math&#x27;, &#x27;course:english&#x27;get &#x27;scores&#x27;, &#x27;Altman&#x27;, [&#x27;grade&#x27;, &#x27;course:math&#x27;, &#x27;course:english&#x27;]get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#123;COLUMN =&gt; &#x27;grade&#x27;&#125;get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#123;COLUMN =&gt; [&#x27;grade&#x27;,&#x27;course:math&#x27;, &#x27;course:english&#x27;]&#125;get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#123;COLUMN =&gt; &#x27;grade&#x27;, TIMESTAMP =&gt; 1624436235582&#125; ## 时间错为毫秒格式get &#x27;scores&#x27;, &#x27;Altman&#x27;, &#123;COLUMN =&gt; &#x27;grade&#x27;, TIMESTAMP =&gt; 1624436235582, VERSIONS =&gt; 4&#125;## scan 命令扫描所有数据, 可以加限定词 TIMERANGE, FILTER, LIMIT, STARTROW, STOPROW, TIMESTAMP, MAXLENGTH, COLUMNSscan &#x27;scores&#x27;scan &#x27;scores&#x27;, &#123;COLUMNS =&gt; [&#x27;grade&#x27;, &#x27;course:math&#x27;], LIMIT =&gt; 10, STARTROW =&gt; &#x27;Altman&#x27;&#125;scan &#x27;scores&#x27;, &#123;COLUMNS =&gt; [&#x27;grade&#x27;], TIMERANGE =&gt; [1624436235582, 1624436335582]&#125;scan &#x27;scores&#x27;, &#123;FILTER =&gt; &quot;(PrefixFilter(&#x27;Al&#x27;) AND (QualifierFilter(&gt;=, &#x27;binary:xzy&#x27;))) AND (TimestampsFilter(123,456))&quot;&#125;## delete 删除指定数据delete &#x27;t1&#x27;, &#x27;r1&#x27;, &#x27;c1&#x27;, ts1delete &#x27;scores&#x27;, &#x27;Altman&#x27;, &#x27;grade&#x27;## deleteall 删除整行数据 慎用deleteall &#x27;scores&#x27;, &#x27;Altman&#x27;## truncate 命令删除全表 , 这个命令其实是 disable drop create 三个命令组合出来的truncate &#x27;scores&#x27;## alter 修改表结构 若 alter 命令执行报错，则先 disable &#x27;scores&#x27;, 再执行 alter 语句, 最后执行 enable &#x27;scores&#x27;### a. 添加一个列族 infoalter &#x27;scores&#x27;, NAME=&gt;&#x27;info&#x27;### b. 修改一个列族 infoalter &#x27;scores&#x27;, NAME=&gt;&#x27;info&#x27;, VERSIONS =&gt; 5### c. 删除一个列族 infoalter &#x27;scores&#x27;, NAME =&gt; &#x27;info&#x27;, METHOD =&gt; &#x27;delete&#x27; alter &#x27;scores&#x27;, &#x27;delete&#x27; =&gt; &#x27;info&#x27;### d. 修改表属性 MAX_FILESIZE, MEMSTORE_FLUSHSIZE, READONLY, DEFERRED_LOG_FLUSHalter &#x27;scores&#x27;, METHOD =&gt; &#x27;table_att&#x27;, MAX_FILESIZE =&gt; &#x27;134217728&#x27;### e. 添加一个表协同处理器 一个表上可以配置多个协同处理器，一个序列会自动增长进行标识。加载协同处理器（可以说是过滤程序）需要符合以下规则：[coprocessor jar file location] | class name | [priority] | [arguments]alter &#x27;scores&#x27;, METHOD =&gt; &#x27;table_att&#x27;, &#x27;coprocessor&#x27; =&gt; ‘hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2′### f. 移除 coprocessoralter &#x27;scores&#x27;, METHOD =&gt; &#x27;table_att_unset&#x27;, NAME =&gt; &#x27;coprocessor$1&#x27;### g. 可以一次执行多个 alter 命令alter &#x27;scores&#x27;, &#123;NAME =&gt; &#x27;new_coloumn&#x27;&#125;, &#123;NAME =&gt; &#x27;info&#x27;, METHOD =&gt; &#x27;delete&#x27;&#125;## count 命令统计行数 count一般会比较耗时，使用mapreduce进行统计，统计结果会缓存，默认是10行。统计间隔默认的是1000行（INTERVAL）count &#x27;scores&#x27;count &#x27;scores&#x27;, INTERVAL =&gt; 100000count &#x27;scores&#x27;, CACHE =&gt; 1000count &#x27;scores&#x27;, INTERVAL =&gt; 100000, CACHE =&gt; 1000## disable 表disable &#x27;scores&#x27;## disable_all 正则匹配disable_all &#x27;t.*&#x27;## is_disabled is_disabled &#x27;scores&#x27;## help 查看帮助文档help help &#x27;alter&#x27; ## 查看 alter 命令的帮助help &#x27;create&#x27; ## 查看 create 命令的帮助## hbase shell 脚本 将一些hbase shell 命令写到一个文件 cmd.txt ，然后顺序执行hbase shell cmd.txt 参考资料使用 Shell 访问HBase shell的基本用法Apache HBase ™ Reference Guide v2.4Learn HBase","categories":[],"tags":[{"name":"Hbase","slug":"Hbase","permalink":"https://altman-xu.github.io/tags/Hbase/"}]},{"title":"算法-排序-归并","slug":"Algorithm-Sort-MergeSort","date":"2021-05-26T08:18:26.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/26/Algorithm-Sort-MergeSort/","link":"","permalink":"https://altman-xu.github.io/2021/05/26/Algorithm-Sort-MergeSort/","excerpt":"","text":"代码使用语言: go (1.13.15)使用工具: GoLang涉及文件: sort_merge.go 测试涉及文件: sotr_test.go 测试输出","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"算法-排序-快排","slug":"ALgorithm-Sort-QuickSort","date":"2021-05-26T07:15:11.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/26/ALgorithm-Sort-QuickSort/","link":"","permalink":"https://altman-xu.github.io/2021/05/26/ALgorithm-Sort-QuickSort/","excerpt":"","text":"代码使用语言: go (1.13.15)使用工具: GoLang涉及文件: sort_quick.go 中枢不动 v1原理: 找到一个中枢，保持不动，把小于中枢的值放到他左边，大于中枢的值放到他右边，然后再以此方法对这两部分数据分别进行快速排序 123456789101112131415func QuickSort_v1_1(array []int, start, end int) &#123; if start &lt; end &#123; key := array[start] // 用待排序数组的第一个作为中枢 i := start for j := start + 1; j &lt;= end; j ++ &#123; // 双指针往后移动 j指针指向&gt;中枢的元素, i指针指向&lt;=中枢的元素, 中枢一直不动，在第一个元素 if key &gt; array[j] &#123; i ++ swap(array, j, i) &#125; &#125; swap(array, i, start) // 将中枢放到指定位置 QuickSort_v1_1(array, start, i - 1) QuickSort_v1_1(array, i + 1, end) &#125;&#125; 此方法与上面 QuickSort_Simple 原理一样，只是换了种写法 12345678910111213141516171819func QuickSort_v1_2(array []int, start, end int) &#123; if start &lt; end &#123; pivot := QuickSort_v1_2_partition(array, start, end) QuickSort_v1_2(array, start, pivot - 1) QuickSort_v1_2(array, pivot + 1, end) &#125;&#125;func QuickSort_v1_2_partition(array []int, start, end int) int&#123; key := array[start] i := start for j := start + 1; j &lt;= end ; j++ &#123; if key &gt; array[j] &#123; i ++ swap(array, j, i) &#125; &#125; swap(array, i, start) return i&#125; 中枢变化 v21234567891011121314151617181920212223242526272829303132333435func QuickSort_v2_1(array []int, start, end int) &#123; if start &lt; end &#123; pivot := QuickSort_v2_1_partition(array, start ,end) QuickSort_v2_1(array, start, pivot - 1) QuickSort_v2_1(array, pivot + 1, end) &#125;&#125;func QuickSort_v2_1_partition(array []int, start, end int) int &#123; pivot := start for start != end &#123; if pivot != end &#123; /** 第一次循环的时候用第一个元素作为中枢，和最后一个进行对比， 如果小于最后一个元素，执行end-- 就是和倒数第二个元素进行对比，以此类推。 如果大于最后一个元素，就和最后一个元素交互，然后让pivot指向最后一个元素 下一轮循环的时候回指向下面的else方法和前面的元素进行对比。 也就是说这个中枢的位置始终是在变动的，所以这一轮执行了之后小于中枢的值就会放到他的前面，大于中枢的值就会放到他的后面 */ if array[end] &lt; array[pivot] &#123; swap(array, end, pivot) pivot = end &#125; else &#123; end -- &#125; &#125; else &#123; if array[start] &gt; array[pivot] &#123; swap(array, start, pivot) pivot = start &#125; else &#123; start ++ &#125; &#125; &#125; return pivot&#125; 123456789101112131415161718192021func QuickSort_v2_2(array []int, start, end int) &#123; if start &lt; end &#123; pivot := QuickSort_v2_2_partition(array, start ,end) QuickSort_v2_2(array, start, pivot - 1) QuickSort_v2_2(array, pivot + 1, end) &#125;&#125;func QuickSort_v2_2_partition(array []int, start, end int) int &#123; pivot := array[start] // 采用子序列的第一个元素作为中枢 for start &lt; end &#123; for start &lt; end &amp;&amp; array[end] &gt;= pivot &#123; // 从后往前在后半部分中寻找第一个小于中枢的元素 end -- &#125; swap(array, start, end) // 将这个元素交换到前半部 for start &lt; end &amp;&amp; array[start] &lt;= pivot &#123; // 从前往后在前半部寻找第一个大于等于中枢的元素 start ++ &#125; swap(array, start, end) // 将这个元素交换到后半部 &#125; return start&#125; 两种结合–最易理解版本原理: 中枢位置不变，中枢之后的元素进行最前和最后的交换，最后再把中枢放到指定位置，相当于上面两种的结合 12345678910111213141516171819func QuickSort_v3_1(array []int, start, end int) &#123; if start &lt; end &#123; pivot, i, j := array[start], start, end // 选定第一个元素为中枢 for i &lt; j &#123; for i &lt; j &amp;&amp; array[j] &gt;= pivot &#123; // 从后往前，找一个比中枢小的元素位置j j -- &#125; for i &lt; j &amp;&amp; array[i] &lt;= pivot &#123; // 从前往后，找一个比中枢大的元素位置i i ++ &#125; if i &lt; j &#123; swap(array, i, j) // 中枢不动，交互 [i j] &#125; &#125; swap(array, i, start) // 中枢动，交互 [i 中枢] QuickSort_v3_1(array, start, i - 1) QuickSort_v3_1(array, i + 1, end) &#125;&#125; 两种结合1234567891011121314151617181920func QuickSort_v3_2(array []int, start, end int) &#123; if start &lt; end &#123; pivot := QuickSort_v3_2_partition(array, start, end) QuickSort_v3_2(array, start, pivot - 1) QuickSort_v3_2(array, pivot + 1, end) &#125;&#125;func QuickSort_v3_2_partition(array []int, start, end int) int &#123; pivot := start for start != end &#123; for start &lt; end &amp;&amp; array[start] &lt; array[pivot] &#123; start ++ &#125; for start &lt; end &amp;&amp; array[end] &gt;= array[pivot] &#123; end -- &#125; swap(array, start, end) &#125; return start&#125; 测试涉及文件: sotr_test.go 1234567891011121314151617181920212223242526272829303132func Test_QuickSort(t *testing.T) &#123; var array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v1_1:%v&quot;, array) QuickSort_v1_1(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v1_1:%v&quot;, array) array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v1_2:%v&quot;, array) QuickSort_v1_2(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v1_2:%v&quot;, array) array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v2_1:%v&quot;, array) QuickSort_v2_1(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v2_1:%v&quot;, array) array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v2_2:%v&quot;, array) QuickSort_v2_2(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v2_2:%v&quot;, array) array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v3_1:%v&quot;, array) QuickSort_v3_1(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v3_1:%v&quot;, array) array = []int&#123;2, 9, -9, 7, -6, 8, 0&#125; t.Logf(&quot;before QuickSort_v3_2:%v&quot;, array) QuickSort_v3_2(array, 0, len(array)-1) t.Logf(&quot;after QuickSort_v3_2:%v&quot;, array)&#125; 测试输出123456789101112131415=== RUN Test_QuickSort--- PASS: Test_QuickSort (0.00s) sotr_test.go:72: before QuickSort_v1_1:[2 9 -9 7 -6 8 0] sotr_test.go:74: after QuickSort_v1_1:[-9 -6 0 2 7 8 9] sotr_test.go:77: before QuickSort_v1_2:[2 9 -9 7 -6 8 0] sotr_test.go:79: after QuickSort_v1_2:[-9 -6 0 2 7 8 9] sotr_test.go:82: before QuickSort_v2_1:[2 9 -9 7 -6 8 0] sotr_test.go:84: after QuickSort_v2_1:[-9 -6 0 2 7 8 9] sotr_test.go:87: before QuickSort_v2_2:[2 9 -9 7 -6 8 0] sotr_test.go:89: after QuickSort_v2_2:[-9 -6 0 2 7 8 9] sotr_test.go:92: before QuickSort_v3_1:[2 9 -9 7 -6 8 0] sotr_test.go:94: after QuickSort_v3_1:[-9 -6 0 2 7 8 9] sotr_test.go:97: before QuickSort_v3_2:[2 9 -9 7 -6 8 0] sotr_test.go:99: after QuickSort_v3_2:[-9 -6 0 2 7 8 9]PASS","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"算法-排序-插入","slug":"Algorithm-Sort-InsertSort","date":"2021-05-19T02:29:45.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/19/Algorithm-Sort-InsertSort/","link":"","permalink":"https://altman-xu.github.io/2021/05/19/Algorithm-Sort-InsertSort/","excerpt":"","text":"代码使用语言: go (1.13.15)使用工具: GoLang涉及文件: sort_insert.go 直接插入12345678910111213141516171819package algorithmfunc InsertSort_simple(array []int) &#123; for i := 1; i &lt; len(array); i++ &#123; key := array[i] j := i for ; j &gt; 0 ; j-- &#123; // array[j-1] &gt; key: (大的往后排--升序) array[j-1] &lt; key: (小的往后排--降序) if array[j-1] &gt; key &#123; array[j] = array[j-1] &#125; else &#123; break &#125; &#125; if i != j &#123; array[j] = key &#125; &#125;&#125; 二分插入1234567891011121314151617181920212223func InsertSort_binary(array []int) &#123; for i := 1; i &lt; len(array); i++ &#123; // array[i] &lt; array[i-1] &amp;&amp; key &lt; array[mid] : (小的往前排--升序) array[i] &gt; array[i-1] &amp;&amp; key &gt; array[mid] : (大的往前排--降序) if array[i] &lt; array[i-1] &#123; key := array[i] low := 0 high := i - 1 for low &lt;= high &#123; mid := low + (high - low)/2 if key &lt; array[mid] &#123; high = mid - 1 &#125; else &#123; low = mid + 1 &#125; &#125; for j := i; j &gt; low; j-- &#123; array[j] = array[j - 1] &#125; array[low] = key &#125; &#125;&#125; 递归版1234567891011121314func InsertSort_recursion(array []int, n int) &#123; if n &lt; 2 &#123; return &#125; n-- InsertSort_recursion(array, n) key := array[n] index := n -1 for index &gt;= 0 &amp;&amp; array[index] &gt; key &#123; array[index + 1] = array[index] index -- &#125; array[index + 1] = key&#125; 测试涉及文件: sotr_test.go 123456789101112131415161718func Test_InsertSort(t *testing.T) &#123; var array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before InsertSort_simple:%v&quot;, array) InsertSort_simple(array) t.Logf(&quot;after InsertSort_simple:%v&quot;, array) array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before InsertSort_binary:%v&quot;, array) InsertSort_binary(array) t.Logf(&quot;after InsertSort_binary:%v&quot;, array) array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before InsertSort_recursion:%v&quot;, array) InsertSort_recursion(array, len(array)) t.Logf(&quot;after InsertSort_recursion:%v&quot;, array)&#125; 测试输出123456789=== RUN Test_InsertSort--- PASS: Test_InsertSort (0.00s) sotr_test.go:55: before InsertSort_simple:[1 0 3 2 4] sotr_test.go:57: after InsertSort_simple:[0 1 2 3 4] sotr_test.go:60: before InsertSort_binary:[1 0 3 2 4] sotr_test.go:62: after InsertSort_binary:[0 1 2 3 4] sotr_test.go:66: before InsertSort_recursion:[1 0 3 2 4] sotr_test.go:68: after InsertSort_recursion:[0 1 2 3 4]PASS","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"算法-排序-选择","slug":"Algorithm-Sort-SelectSort","date":"2021-05-18T06:35:01.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/18/Algorithm-Sort-SelectSort/","link":"","permalink":"https://altman-xu.github.io/2021/05/18/Algorithm-Sort-SelectSort/","excerpt":"","text":"代码使用语言: go (1.13.15)使用工具: GoLang涉及文件: sort_bubble.go 12345678910111213141516package algorithmfunc SelectSort(array[]int) &#123; for i := 0; i &lt; len(array); i++ &#123; index := i for j := i + 1; j &lt; len(array); j++ &#123; // array[index] &gt; array[j]:(大的往后排--升序) array[index] &lt; array[j]:(小的往后排--降序) if array[index] &gt; array[j] &#123; index = j; &#125; &#125; if i != index &#123; swap(array, i, index) &#125; &#125;&#125; 测试涉及文件: sotr_test.go 123456789101112131415161718package algorithmimport ( &quot;testing&quot;)func Test_SelectSort(t *testing.T) &#123; var array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before SelectSort:%v&quot;, array) SelectSort(array) t.Logf(&quot;after SelectSort:%v&quot;, array) array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before SelectSort_recursion:%v&quot;, array) SelectSort_recursion(array, 0) t.Logf(&quot;after SelectSort_recursion:%v&quot;, array)&#125; 测试输出1234567=== RUN Test_SelectSort--- PASS: Test_SelectSort (0.00s) sotr_test.go:40: before SelectSort:[1 0 3 2 4] sotr_test.go:42: after SelectSort:[0 1 2 3 4] sotr_test.go:45: before SelectSort_recursion:[1 0 3 2 4] sotr_test.go:47: after SelectSort_recursion:[0 1 2 3 4]PASS","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"算法-排序-冒泡","slug":"Algorithm-Sort-BubbleSort","date":"2021-05-17T04:16:57.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/17/Algorithm-Sort-BubbleSort/","link":"","permalink":"https://altman-xu.github.io/2021/05/17/Algorithm-Sort-BubbleSort/","excerpt":"","text":"代码使用语言: go (1.13.15)使用工具: GoLang涉及文件: sort_bubble.go 123456789package algorithmfunc swap(array []int, i, j int) &#123; if (i != j) &#123; // 一定要检查两个地址是否相同，否则若两个相同，改地址数据会被 异或 清零 array[i] ^= array[j] array[j] ^= array[i] array[i] ^= array[j] &#125;&#125; 普通版本 往前排1234567891011// 往前排func BubbleSort_front(array []int) &#123; for i := 0; i &lt; len(array)-1; i++ &#123; for j := i + 1; j &lt; len(array); j++ &#123; // array[j] &lt; array[i]:(小的往前排--升序) array[j] &gt; array[i]:(大的往前排--降序) if array[j] &lt; array[i] &#123; swap(array, i, j) &#125; &#125; &#125;&#125; 普通版本 往后排1234567891011// 往后排func BubbleSort_back(array []int) &#123; for i := 1; i &lt; len(array); i++ &#123; for j := 0; j &lt; len(array)-i; j++ &#123; // array[j] &gt; array[j + 1]:(大的往后排--升序) array[j] &lt; array[j + 1]:(小的往后排--降序) if array[j] &gt; array[j+1] &#123; swap(array, j, j+1) &#125; &#125; &#125;&#125; 优化版本1234567891011121314151617// 优化 (当后面的已经排序好的时候，可提前终止循环)func BubbleSort_optimize(array []int) &#123; var location int var count = len(array) - 1 // 初始化最后交换位置为最后一个元素 for i := 0; i &lt; len(array) - 1; i++ &#123; location = count for j := 0; j &lt; location; j++ &#123; if array[j] &gt; array[j + 1] &#123; swap(array, j, j + 1) count = j // 记录无需位置的结束，有序从 j+1 位置开始 &#125; &#125; if count == location &#123; // 没有次序交换，排序完成 break &#125; &#125;&#125; 递归版本1234567891011121314// 递归版本func BubbleSort_recursion(array []int, n int) &#123; if n == 1 || len(array) == 0 &#123; return &#125; // 逐渐减少n,每次都把最大的放到最后面,直到n为1 for i := 0; i &lt; n - 1; i++ &#123; if array[i] &gt; array[i + 1] &#123; swap(array, i, i + 1) &#125; &#125; BubbleSort_recursion(array, n - 1)&#125; 测试涉及文件: sotr_test.go 12345678910111213141516171819202122package algorithmimport ( &quot;testing&quot;)func Test_bubbleSort(t *testing.T) &#123; var array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before BubbleSort_front:%v&quot;, array) BubbleSort_front(array) t.Logf(&quot;after BubbleSort_front:%v&quot;, array) array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before BubbleSort_back:%v&quot;, array) BubbleSort_back(array) t.Logf(&quot;after BubbleSort_back:%v&quot;, array) array = []int&#123;1,0,3,2,4&#125; t.Logf(&quot;before BubbleSort_recursion:%v&quot;, array) BubbleSort_recursion(array, len(array)) t.Logf(&quot;after BubbleSort_recursion:%v&quot;, array)&#125; 测试输出123456789=== RUN Test_bubbleSort--- PASS: Test_bubbleSort (0.00s) sotr_test.go:22: before BubbleSort_front:[1 0 3 2 4] sotr_test.go:24: after BubbleSort_front:[0 1 2 3 4] sotr_test.go:27: before BubbleSort_back:[1 0 3 2 4] sotr_test.go:29: after BubbleSort_back:[0 1 2 3 4] sotr_test.go:32: before BubbleSort_recursion:[1 0 3 2 4] sotr_test.go:34: after BubbleSort_recursion:[0 1 2 3 4]PASS","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"算法 交换两个整数","slug":"Switch-Two-Values","date":"2021-05-16T02:41:14.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/16/Switch-Two-Values/","link":"","permalink":"https://altman-xu.github.io/2021/05/16/Switch-Two-Values/","excerpt":"","text":"参考资料 经典的XOR异或交换算法 1.如果你用这个办法交换2个指针的内容.那么你要先检查2个指针指向的地址是否相同.不然会导致内容被清0 2.速度并不比朴素的中间变量交换快. 结论.别这么干.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"}]},{"title":"消息摘要、数字签名、数字证书","slug":"Digital-Certificate","date":"2021-05-14T09:44:29.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/05/14/Digital-Certificate/","link":"","permalink":"https://altman-xu.github.io/2021/05/14/Digital-Certificate/","excerpt":"","text":"消息摘要消息摘要算法是密码学算法中非常重要的一个分支，它通过对所有数据提取指纹信息以实现数据签名、数据完整性校验等功能，由于其不可逆性，有时候会被用做敏感信息的加密。 消息摘要算法也被称为哈希(Hash)算法或散列算法。 任何消息经过散列函数处理后，都会获得唯一的散列值，这一过程称为消息摘要，其散列值称为数字指纹，其算法自然就是消息摘要算法了。换句话说，如果其数字指纹一致，就说明其消息是一致的。 消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密，目前可以解密逆向的只有 CRC32 算法，只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文。 消息摘要算法不存在密钥的管理与分发问题，适合于分布式网络上使用。 消息摘要算法主要应用在数字签名领域，作为对明文的摘要算法。 著名的摘要算法有 RSA 公司的 MD5 算法和 SHA-1 算法及其大量的变体。 (数字证书及CA详解)[https://blog.csdn.net/lk2684753/article/details/100160856] ()[https://cloud.tencent.com/developer/article/1584742#:~:text=%E6%B6%88%E6%81%AF%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95%E6%98%AF%E5%AF%86%E7%A0%81,%E7%AE%97%E6%B3%95%E6%88%96%E6%95%A3%E5%88%97%E7%AE%97%E6%B3%95%E3%80%82] (数字签名、数字证书与HTTPS是什么关系？)[https://www.zhihu.com/question/52493697/answer/1600962734] 极客时间之分布式协议与算法实战 18 Hashicorp Raft 二 如何以集群节点为中心使用API","categories":[],"tags":[{"name":"Digital-Certificate","slug":"Digital-Certificate","permalink":"https://altman-xu.github.io/tags/Digital-Certificate/"}]},{"title":"Kafka-原理","slug":"Kafka-Principle","date":"2021-04-22T03:26:23.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/04/22/Kafka-Principle/","link":"","permalink":"https://altman-xu.github.io/2021/04/22/Kafka-Principle/","excerpt":"","text":"Customer Group 消费者组Customer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制 重要特征 组内可以有多个消费者实例（Consumer Instance） 消费者组的唯一标识被称为Group ID，组内的消费者共享这个公共的ID 消费者组订阅主题，主题的每个分区只能被组内的一个消费者消费 消费者组机制，同时实现了消息队列模型和发布/订阅模型 若所有实例都属于一个 Group, 则实现消息队列模型若所有实例分别属于不同 Group, 则实现发布/订阅模型 Customer Group 的 Customer 数量理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数 假设一个 Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数依次是 1、2、3（总共是 6 个分区）若设置 6 个 Consumer 实例，则平均每个示例消费 6/6=1 个分区，是理想情形，最大限度地实现高伸缩性若设置 3 个 Consumer 实例，则平均每个示例消费 6/3=2 个分区若设置 8 个 Consumer 实例，则会浪费 8-6=2 个 Customer 示例，他们不会被分配到任何分区，永远空闲 Rebalance 重平衡本质本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区 触发条件 组成员数发生变更 比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组 订阅主题数发生变更 Consumer Group 可以使用正则表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance 订阅主题的分区数发生变更 Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance 分配策略Rebalance 发生时，Group 下所有的 Consumer 实例都会协调在一起共同参与，根据分配策略的协助， 给每个 Consumer 实例分配对应的主题分区 缺点 Stop The World 在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成，耗时长 所有 Customer 全部重新分配分区 更高效的做法是尽量减少分配方案的变动。例如实例 A 之前负责消费分区 1、2、3，那么 Rebalance 之后，如果可能的话，最好还是让实例 A 继续消费分区 1、2、3，而不是被重新分配其他的分区。这样的话，实例 A 连接这些分区所在 Broker 的 TCP 连接就可以继续用，不用重新创建连接其他 Broker 的 Socket 资源。 Offset 位移","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://altman-xu.github.io/tags/Kafka/"}]},{"title":"Kafka-基本概念","slug":"Kafka-Concept","date":"2021-04-21T03:08:07.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/04/21/Kafka-Concept/","link":"","permalink":"https://altman-xu.github.io/2021/04/21/Kafka-Concept/","excerpt":"","text":"Producer生产者 Consumer消费者 Consumer Group说明: 一个消费者组，由多个consumer组成，消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内的消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，及消费者组是逻辑上的一个订阅者。 一个partition分区中的消息只能被某一个消费者组中的一个消费者消费。这样设计的目的是为了提高消费者组的并发度。 当一个消费者组中的消费者个数与主题的分区数一致时才最合理，如果消费者个数过多就造成了性能浪费。 注: kafka 允许一个 topic 被多个消费者组消费，这种情况下。 假如topic有10条消息，则消费组A里面的所有消费者消费10条数据；消费组B里面所有消费者消费10条数据。即一条消息可以被多给消费组重复消费(在同一个消费组内，一条消息只会被组内的一个消费组消费) Broker说明: 一台kafka服务器就是一个broker。一个集群由多个broker组成，一个broker容纳多个topic Topic说明: 可以理解为队列，生产者和消费者都是面向topic Replica:副本机制目的: 保证数据持久化或消息不丢失 同类: MySQL的主从同步(注:mysql从库可以支持读操作，不支持写操作) 说明: 备份即将相同数据拷贝到多台机器上，这些相同数据拷贝在kafka中被称为副本(Replica), kafka定义了以下两类副本: 领导者副本(Leader Replica) 前者对外提供服务(处理读写消息) 追随者副本(Follower Replica) 不提供任何服务,仅向leader发送请求，同步最新数据，当leader发生故障，某个Follower会成为新的Leader 限制: 同一主题的同一分区的leader和follower一定不在同一台机器上 限制: 创建topic时指定的副本数量，不能超过集群中的broker数量。 (分区数量则没限制，单机也可以创建多分区的topic) 12345➜ bin kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 3 --topic test2Error while executing topic command : Replication factor: 3 larger than available brokers: 1.[2021-04-09 11:59:26,516] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1. (kafka.admin.TopicCommand$)➜ bin Partition:分区机制目的: 解决服务伸缩性问题(Scalability)。 提高主题Topic的负载能力。消息会轮询发送到同一Topic主题在不同Broker中的不同Partition分区中 同类: 类似 MongoDb 和 Elasticsearch 中的 Sharding , Hbase 中的 Region 说明: kafka将topic划分成多个partition，每个partition是一组有序的消息日志。生产者往名称为A的topic生产的一条消息，改消息只能被发送到Atopic一个分区 副本是在分区这个层级定义的，每个分区可配置若干个副本，其中只能有一个leader副本，N-1个follower副本。 重复消费整个故事是这样的：假设C1消费P0,P1, C2消费P2,P3。如果C1从未提交，C1挂掉，C2开始消费P0,P1，发现没有对应提交位移，那么按照C2的auto.offset.reset值决定从那里消费，如果是earliest，从P0，P1的最小位移值（可能不是0）开始消费，如果是latest，从P0, P1的最新位移值（分区高水位值）开始消费。但如果C1之前提交了位移，那么C1挂掉之后C2从C1最新一次提交的位移值开始消费。 所谓的重复消费是指，C1消费了一部分数据，还没来得及提交这部分数据的位移就挂了。C2承接过来之后会重新消费这部分数据。 kafka的3层消息架构第一层: 主题层(Topic)，每个主题可以配置M个分区，而每个分区可以配置N个副本 第二层: 分区层(Partition)，每个分区的N个副本中只有一个充当Leader角色，对外提供服务；其他N-1个副本是Follower角色，只提供数据冗余 第三层: 消息层(Message)，分区中包含若干条消息，每条消息的位移从0开始，依次递增 持久化数据Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。 数据删除(日志删除)通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。 重平衡：Rebalance消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。 消息模型传统的消息队列最少提供两种消息模型，一种P2P，一种PUB/SUB，而Kafka并没有这么做，巧妙的，它提供了一个消费者组的概念，一个消息可以被多个消费者组消费，但是只能被一个消费者组里的一个消费者消费，这样当只有一个消费者组时就等同与P2P模型，当存在多个消费者组时就是PUB/SUB模型 消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。 每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://altman-xu.github.io/tags/Kafka/"}]},{"title":"本博客搭建:PicGo+GitHub作为图床","slug":"Build-Blog-Picture","date":"2021-04-20T02:32:37.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/04/20/Build-Blog-Picture/","link":"","permalink":"https://altman-xu.github.io/2021/04/20/Build-Blog-Picture/","excerpt":"","text":"博客的图床，又在白嫖 GitHub 了 参考链接 如何使用 Github 作为自己的免费图床PicGo 文档:配置手册 GitHub 仓库 Image在 GitHub 上新建仓库，仓库名为 Image (或自定义)，然后无需其他操作 GitHub 配置 Personal access tokens在 GitHub 右上角头像单击，然后 Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Generate new token 进入编辑页面Note: 名字可以随便填写，如 Image、PhotoSelect scopes: 选择 repo 即可然后点击按钮 Generate token 在跳转出来的页面， 将 Token 值 保存起来，后面 配置 PicGo 时用到 PicGo 使用 安装 PicGo 1brew install --cask picgo 配置 PicGo打开 PicGo 软件， Mac 屏幕上方状态栏会出现 PicGo 小图标， 右击图标-&gt;打开详细窗口-&gt;图床设置-&gt;GitHub图床 (如下截图所示界面)设定Token 一栏中填入 上面步骤生成的 Token 值 使用 PicGo将待上传的图片拖动到 Mac 屏幕上方状态栏的 PicGo 小图标(会出现 + 添加图片的标志)，在 + 标志处松开鼠标即为上传然后单击 PicGo 小图标，出现刚刚上传图片的 缩略图， 单击缩略图，即会复制图片链接链接格式可以是 markdown/HTML/URL/UBB/Custom 等 在 右击图标-&gt;打开详细窗口-&gt;上传区可设置","categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"}]},{"title":"本博客搭建:Hexo+GithubPages+TraviCI+pure","slug":"Build-Blog-Hexo-GithubPages-TraviCI-Pure","date":"2021-04-19T03:50:43.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/04/19/Build-Blog-Hexo-GithubPages-TraviCI-Pure/","link":"","permalink":"https://altman-xu.github.io/2021/04/19/Build-Blog-Hexo-GithubPages-TraviCI-Pure/","excerpt":"","text":"最终目的流程 在本地hexo仓库新建博客文件 Hexo new &quot;new-blog-post-name&quot; 在本地疯狂编辑博客内容 new-blog-post-name.md 在本地部署查看效果 hexo s 然后访问 http://localhost:4000/ 查看最新文章在本地效果是否满意(此步骤可省略) push 本地 hexo 仓库到 github 上 远程 Travis CI 自动触发 CI, 将源码 md 文件通过 hexo 编译为 html文件, 更新 GitHub Pages 内容 访问浏览器查看到新内容 本地环境说明 本机电脑: macOS Catalina Version 10.15.7 Git 1234## 安装: Mac电脑自带 Git,若无请手动安装 ## 版本➜ git --versiongit version 2.24.3 (Apple Git-128) node 12345## 安装: ➜ brew install node## 版本➜ git --versiongit version 2.24.3 (Apple Git-128) npm 12345## 安装: ➜ brew install node## 版本➜ npm -v7.7.6 hexo 123456## 安装➜ npm install -g hexo-cli➜ npm install -g hexo## 版本➜ ~ hexo -versionhexo-cli: 4.2.0 Hexo 本地初始化站点12cd /Users/zhihua.xu/Documents/ ## 笔者将站点放在 Documents 目录下， 这个可以每个人自定义hexo init altman-xu.github.io ## hexo 站点名字， 起名为这个是因为后面 github 仓库名也是这个 修改 站点的 _config.yml最主要就修改下面这些数据, 注意使用的主题改为 pure 1234567891011title: Altman&#x27;s Blogsubtitle: &#x27;&#x27;description: &#x27;&#x27;keywords:author: Altmanlanguage: en ## zh-CN entimezone: &#x27;Asia/Shanghai&#x27;url: https://altman-xu.github.io/theme: pure pure 站点主题 theme-suka Sukka’s Blogtheme-next 展示theme-pure 展示 对比了这三个主题，最终还是选择 pure 个人比较喜欢 12345678# 当前目录为 hexo 站点根目录: /Users/zhihua.xu/Documents/altman-xu.github.iogit clone https://github.com/cofess/hexo-theme-pure.git themes/purecd themes/puregit pull## 启动本地 hexo 服务hexo s --debug ## 部署站点，然后访问 http://localhost:4000/ 查看站点效果 接着 参照 Hexo博客主题pure使用说明 博客内容修改 pure 目录下的 _config.yml 文件pure 目录下的 /source/images 部分图片也替换成自己的在修改过程，有些修改重刷页面即可看到效果，有些需要重启服务 本地安装插件说明 hexo-wordcount 作用: 字数统计、阅读时长预计 1npm install hexo-wordcount --save hexo-generator-json-content 作用: 站内搜索 1npm install hexo-generator-json-content --save hexo-generator-feed 作用: Generate Atom 1.0 or RSS 2.0 feed 1npm install hexo-generator-feed --save hexo-generator-sitemap 作用: Generate sitemap – 针对谷歌 使用站图的初衷是为自己的博客添加站内搜索,如果想更好的发挥站图的作用 1npm install hexo-generator-sitemap --save hexo-generator-sitemap 作用: Generate sitemap – 针对百度 使用站图的初衷是为自己的博客添加站内搜索,如果想更好的发挥站图的作用，建议手动提交baidusitemap给百度. 1npm install hexo-generator-baidu-sitemap --save 本地pure主题修改 pure 目录下的 /source/images 部分图片也替换成自己的其余修改参照 Hexo博客主题pure使用说明 评论设置之前想的是使用 gitalk 作为评论方案，可以用github登录更 programer, 但是遇到太多问题，故还是使用国外的 Disqus gitalk Error: Not Found.gitalk 解决配置gitalk插件后初始化登录时跳转回首页gitalk 评论登录 403 问题解决 现在 Disqus[https://disqus.com/] 上新建一个站点名称为 altman-xu.github.io 可参照这个 Hexo 集成 Disqus 评论 修改 pure 下的 _config.yml 即可 123comment:type: disqus # 启用哪种评论系统 ## gitalk proxy 频频报错，故改用 disqusdisqus: altman-xu-github-io # enter disqus shortname here GitHub Pages在 github 上新建仓库, 仓库名为 username.github.io 12345678910111213141516171819202122232425262728# 当前目录为 hexo 站点根目录# 添加 Github 仓库到本地git remote add origin https://github.com/altman-xu/altman-xu.github.io.git# 编辑 .gitignore 文件, 如果没有，则手动创建这个文件， 文件内容如下， 注 一定不要有 themes/ 即我们要把这个文件夹下所有内容添加到 git 上(因为我们使用的 pure 主题，修改了源文件，也不想在 ci 过程中重新去 github 拉取).DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/## 去除 themes/pure 的 git 关联，改内容是从 git clone 过来的，现在我们改了内容，要 push 到我们自己的仓库中, 先将整个 themes/pure 文件备份一份，避免接下来操作出现问题rm -rf themes/pure/.gitrm -rf themes/pure/.gitignoregit rm --cached themes/pure/ -f ## 干掉 submodule 关联，不执行这一步， 下面 push 时候会提示 fatal: in unpopulated submodule 这个错误# 新建一个名为 source 的分支git checkout -b source# 将所有文件添加到 gitgit add .# 添加 commitgit commit -m &quot;initial&quot;# 将本地的文件推送到 Github 上的 source 分支git push -u origin source## 注意去远程仓库看 themes/pure/ 下有没有内容 Travis CI 自动化部署方案 将 Travis CI 添加到你的 Github 账户 , 添加 Open Source, 其他都要收费 去 Applications settings 设置让 Travis CI 能够访问你的 repo 去 Personal access tokens 为 Travis CI 新建一个 token ( 只需要 repo 这个 scopes )，然后把 token 的值记录下来 去 Travis CI，在你的 repo 页面下点击 More Options 找到 Settings， 然后在 Environment Variables 下新建一个环境变量，Name 为 GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token。确保 DISPLAY VALUE IN BUILD LOG 保持 不被勾选 避免你的 Token 泄漏。点击 Add 保存 在你的 Github 的项目 source 分支内新建一个名为 .travis.yml 的文件，参考以下内容进行填入 1234567891011121314151617181920212223242526272829303132333435363738394041424344os: linuxlanguage: node_js node_js:- 10 # 使用 nodejs LTS v10branches:only: - source # 只监控 source 的 branchcache:directories: - node_modules # 缓存 node_modules 加快构建速度before_script: ## 根据你所用的主题和自定义的不同，这里会有所不同 # 使用 themes/suka 是使用的 ci 脚本 begin # - npm install -g hexo-cli # 在 CI 环境内安装 Hexo # - mkdir themes # 由于我们没有将 themes/ 上传，所以我们需要新建一个 # - cd themes # - git clone https://github.com/SukkaW/hexo-theme-suka.git suka #从 Github 上拉取 Suka 主题 # - cd suka # - npm install --production # 安装 Suka 主题的依赖 # - cd ../.. # 返回站点根目录 # - cp _config.theme.yml themes/suka/_config.yml # 将主题的配置文件放回原处 # - npm install # 在根目录安装站点需要的依赖 # 使用 themes/suka 是使用的 ci 脚本 end # 使用 themes/pure 是使用的 ci 脚本 begin ## 注: 与 suka 最大的区别是 themes 不从 Github 上拉取，而是使用自己仓库里的 原因是修改了一些源码和图片 - npm install -g hexo-cli # 在 CI 环境内安装 Hexo - npm install hexo-wordcount --save # 安装插件 hexo-wordcount - npm install hexo-generator-json-content --save # 安装插件 hexo-generator-json-content - npm install hexo-generator-feed --save # 安装插件 hexo-generator-feed - npm install hexo-generator-sitemap --save # 安装插件 hexo-generator-sitemap - npm install hexo-generator-baidu-sitemap --save # 安装插件 hexo-generator-baidu-sitemap - npm install # 在根目录安装站点需要的依赖 # 使用 themes/pure 是使用的 ci 脚本 endscript: - hexo generate # generate static filesdeploy: # 根据个人情况，这里会有所不同provider: pagesskip_cleanup: true # 构建完成后不清除token: $GH_TOKEN # 你刚刚设置的 tokenkeep_history: true # 保存历史# fqdn: blog.ne0ng.page # 自定义域名，使用 username.github.io 可删除on: branch: source # hexo 站点源文件所在的 branchlocal_dir: public target_branch: master # 存放生成站点文件的 branch，使用 username.github.io 必须是 master 将 .travis.yml 推送到 repository 中。Travis CI 应该会自动开始运行，并将生成的文件推送到同一 repository 下的 master 分支下 在 GitHub 中前往你的 repository 的 Settings-Pages ，修改 GitHub Pages 的部署分支为 master 在 GitHub 中前往你的 repository 的 Branches, 将 Default Branch 修改为 master 分支 前往 https://altman-xu.github.io 查看你的站点是否可以访问。这可能需要一些时间。 也可以本地修改内容或 hexo new postArticle 然后推送git 重新触发 ci， 然后去 Travis CI 上看构建情况 是否报错 部署方案另外的选择 hexo d参照 mac下搭建hexo+github 示例通过 hexo g &amp;&amp; hexo d 将生成的静态html文件部署上git上注: 这种方式没有将 源码文件也放到git上我们上面的 通过 Travis CI 方式，将源码文件和生成的静态html文件都放到git上,更优雅; 在另外的机器上重新搭建写hexo也更方便 问题说明 文章名字建议用全英文 hexo new “postArticleName” 新建文章时候，命令里的 postArticleName 文章名字使用 全英文 然后在 _post 里面对应的 md 里面的 title， 可以使用想用的中文，避免gittalk转链接和长度限制错误 hexo 常用命令12345678hexo new &quot;postArticleName&quot; # 新建文章hexo new page &quot;postArticleName&quot; # 新建页面hexo s # 简写 hexo server # 开启预览访问端口（默认端口4000，&#x27;ctrl + c&#x27;关闭server）,可边修改配置边预览hexo g # 简写 hexo generate # 生成静态页面至public目录hexo d # 简写 hexo deploy # 将.deploy目录部署到GitHubhexo help # 查看帮助hexo clean ## 清楚缓存文件(db.json)和已生成的静态文件(public)hexo version # 查看Hexo的版本 hexo 模板修改修改站点目录下的 /scaffolds/post.md , 改为如下内容, 优化 hexo new &quot;postArticleName&quot; 新创建文章的初始化内容 12345678910111213---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags: ## tags 多个的话, 分多行显示 - tag1_PleaseDelete - tag2_PleaseDeletecategories: # 目录暂不启用, 现主要使用 tag区分toc: true # 是否启用内容索引 (每个文字页面下面的 Catalogue/文章目录)---## ## 图床本博客搭建:PicGo+GitHub作为图床 参考链接 Hexo 文档Travis CI 加 Hexo 实现自动构建部署 Github Pages 博客将 Hexo 部署到 GitHub PagesHexo 集成 Disqus 评论","categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://altman-xu.github.io/tags/Hexo/"},{"name":"TraviCI","slug":"TraviCI","permalink":"https://altman-xu.github.io/tags/TraviCI/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-04-16T01:02:29.000Z","updated":"2023-11-08T10:00:20.896Z","comments":true,"path":"2021/04/16/hello-world/","link":"","permalink":"https://altman-xu.github.io/2021/04/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"}]}],"categories":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/categories/Blog/"},{"name":"Life","slug":"Life","permalink":"https://altman-xu.github.io/categories/Life/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/categories/Algorithm/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://altman-xu.github.io/tags/Blog/"},{"name":"Life","slug":"Life","permalink":"https://altman-xu.github.io/tags/Life/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://altman-xu.github.io/tags/Elasticsearch/"},{"name":"assembly","slug":"assembly","permalink":"https://altman-xu.github.io/tags/assembly/"},{"name":"k8s","slug":"k8s","permalink":"https://altman-xu.github.io/tags/k8s/"},{"name":"Hbase","slug":"Hbase","permalink":"https://altman-xu.github.io/tags/Hbase/"},{"name":"Sort","slug":"Sort","permalink":"https://altman-xu.github.io/tags/Sort/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://altman-xu.github.io/tags/Algorithm/"},{"name":"Digital-Certificate","slug":"Digital-Certificate","permalink":"https://altman-xu.github.io/tags/Digital-Certificate/"},{"name":"Kafka","slug":"Kafka","permalink":"https://altman-xu.github.io/tags/Kafka/"},{"name":"Hexo","slug":"Hexo","permalink":"https://altman-xu.github.io/tags/Hexo/"},{"name":"TraviCI","slug":"TraviCI","permalink":"https://altman-xu.github.io/tags/TraviCI/"}]}